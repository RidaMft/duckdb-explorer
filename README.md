# ğŸ¦† SQL Explorer â€“ Multiâ€‘source (DuckDB + Streamlit)

Un miniâ€‘**Dremioâ€‘like** openâ€‘source pour **explorer, joindre et profiler** des donnÃ©es locales et externes, avec **DuckDB** comme backend persistant.

> **Points clÃ©s**
> - Chargez **plusieurs CSV** (sÃ©parateurs multiâ€‘caractÃ¨res supportÃ©s)
> - Connectez des **bases externes** via **SQLAlchemy** *ou* directement via les **extensions DuckDB** (Postgres/MySQL/SQLite)
> - ExÃ©cutez des **requÃªtes SQL** entre **toutes** vos sources
> - Inspectez **schÃ©mas** et **stats** (profilage)
> - **Comparez** et **fusionnez** 2 tables
> - **Exportez** vos tables en **Parquet/CSV** et **compactez** la base (VACUUM)

---

## ğŸ¯ Pourquoi utiliser ce projet ?

### 1) RapiditÃ© & simplicitÃ©
**DuckDB** est une base **embarquÃ©e** optimisÃ©e OLAP : zeroâ€‘serveur, trÃ¨s rapide sur fichiers locaux (CSV/Parquet/JSON) et DataFrames. Vous obtenez une **expÃ©rience interactive** faÃ§on â€œSQL Workbenchâ€ sans infra lourde.

### 2) Multiâ€‘sources, requÃªtes croisÃ©es
Joignez en SQL des tables **CSV**, des rÃ©sultats **ingÃ©rÃ©s via SQLAlchemy**, et des **schÃ©mas attachÃ©s** en live (Postgres/MySQL/SQLite) via les **extensions DuckDB** â†’ un seul **catalogue DuckDB**.

### 3) Profilage & gouvernance lÃ©gÃ¨re
Inspectez vos colonnes (**types, nulls, stats numÃ©riques, top catÃ©gories**), comparez 2 tables (antiâ€‘join), fusionnez (INNER/LEFT/RIGHT/FULL), puis **exportez**/**versionnez**.

### 4) Devâ€‘friendly & portable
Tout est **Python + Streamlit** : facile Ã  Ã©tendre, connecteurs SQLAlchemy classiques, **Docker** pour un dÃ©marrage en 1 commande.

---

## ğŸ§± Architecture

- **Frontend** : Streamlit (onglets *Sources, SQL, SchÃ©ma, Profilage, Comparer, Fusionner, Source externe, Extensions ATTACH*)
- **Backend** : DuckDB persistant (`data/catalog.duckdb`) + utilitaires (profilage, export, attach, ingestion SQLAlchemy)
- **Extensions DuckDB** : `postgres`, `mysql`, `sqlite`, `httpfs`, `json` (activables depuis lâ€™UI)

---

## ğŸš€ DÃ©marrage (local)

```bash
# 1) CrÃ©ez et activez votre venv (recommandÃ©)
python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 2) Installez les dÃ©pendances
pip install -r requirements.txt

# 3) Lancez l'app
streamlit run app.py
```

Ouvrez lâ€™URL affichÃ©e (par dÃ©faut http://localhost:8501). Dans la barre latÃ©rale :
1) **(Re)connecter** DuckDB (chemin modifiable, ex. `data/catalog.duckdb`)  
2) **Activer extensions** (Postgres/MySQL/SQLite/httpfs/json)  
3) **Charger CSV (multi)**  

---

## ğŸ³ DÃ©marrage avec Docker

```bash
# Build
docker build -t duckdb-sql-explorer .

# Run (port 8501, volumes pour persistance et exports)
docker run -it --rm \
  -p 8501:8501 \
  -v $PWD/data:/app/data \
  -v $PWD/exports:/app/exports \
  --name duckdb-sql-explorer \
  duckdb-sql-explorer
```

Ou via **docker-compose** :

```bash
docker compose up --build -d
```

> Les **extensions DuckDB** sont installÃ©es/chargÃ©es dynamiquement (nÃ©cessitent lâ€™accÃ¨s Internet au dÃ©pÃ´t des extensions). Vous pouvez les activer depuis lâ€™UI.

---

## ğŸ”Œ Connexions externes

### Via SQLAlchemy (ingestion â†’ DuckDB)
Onglet **Source externe â†’ DuckDB** : renseignez une **URL SQLAlchemy** (ex. `postgresql+psycopg2://user:pass@host:5432/db`), puis saisissez une **table** *ou* une **requÃªte SELECT** ; ciblez une table DuckDB (`replace|append|create`).

### Via extensions DuckDB (ATTACH en live)
Onglet **Extensions ATTACH** : choisissez le type (`postgres|mysql|sqlite`), lâ€™alias et la connexion/libpqâ€‘string (ou le fichier SQLite). Une fois attachÃ©e, requÃªtez `alias.schema.table` directement (sans ingestion).

---

## ğŸ“¦ Export & maintenance

- **Export** : *Sources â†’ Exporter une table* â†’ Parquet/CSV (`exports/â€¦`)  
- **Compactage** : bouton **VACUUM** pour rÃ©duire lâ€™empreinte disque de `data/catalog.duckdb`

---

## ğŸ” Secrets & sÃ©curitÃ©

- Ã‰vitez de mettre des mots de passe en dur dans lâ€™UI : prÃ©fÃ©rez **variables dâ€™environnement** / fichiers **`.env`** (supportÃ©s par Docker Compose).  
- Postgres/MySQL via ATTACH : utilisez de prÃ©fÃ©rence des **chaÃ®nes libpq** et limitez Ã  un **schÃ©ma** si la base est volumineuse.

---

## âš ï¸ Limites & bonnes pratiques

- **ATTACH (live)** sur bases distantes est pratique, mais pour des workloads importants, **ingÃ©rez** (matÃ©rialisez) dans DuckDB pour gagner en stabilitÃ© et reproductibilitÃ©.
- Sur CSV volumineux avec **sÃ©parateurs multiâ€‘caractÃ¨res**, gardez le mode *literal* (plus sÃ»r pour les quotes).

---

## ğŸ¤ Contribuer
PRs/Issues bienvenues ! Merci dâ€™ouvrir une issue avec un **exemple minimal** (fichier, requÃªte, log) pour accÃ©lÃ©rer le debug.

---

## ğŸ“œ Licence
MIT
